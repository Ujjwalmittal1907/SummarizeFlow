# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j2T2uFiZhsVReyAkc0JcD2h4_FlqqzX6
"""

!pip install -q transformers

!pip install -q youtube_transcript_api

from transformers.pipelines import pipeline
from youtube_transcript_api import YouTubeTranscriptApi

youtube_video = "https://www.youtube.com/watch?v=tdHOSuMfM5w"

video_id = youtube_video.split("=")[1]

video_id

from IPython.display import YouTubeVideo
YouTubeVideo(video_id)

YouTubeTranscriptApi.get_transcript(video_id)
transcript = YouTubeTranscriptApi.get_transcript(video_id)

transcript

text = ""
for i in transcript:
    text += ' ' + i['text']
print(text)
print(len(text))

!pip install transformers==2.8.0
!pip install torch

!pip install --upgrade tensorflow
!pip install --upgrade keras
import torch
from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config

# initialize the pretrained model
model = T5ForConditionalGeneration.from_pretrained('t5-small')
tokenizer = T5Tokenizer.from_pretrained('t5-small')
device = torch.device('cpu')

## preprocess the input text
preprocessed_text = text.strip().replace('\n','')
t5_input_text = 'summarize: ' + preprocessed_text

t5_input_text

len(t5_input_text.split())

tokenized_text = tokenizer.encode(t5_input_text, return_tensors='pt', max_length=512).to(device)

summary_ids = model.generate(tokenized_text, min_length=30, max_length=120)
summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)

summary

